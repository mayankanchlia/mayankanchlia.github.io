---
permalink: /projects/
title: "Projects"
excerpt: "Projects"
author_profile: true
redirect_from: 
  - /projects.html/
---

**Research/Industry projects**
* **Intelligent Human Pose Recommendation using Tensorflow**  
○ Leveraged skeleton data to ​ classify and recommend the best pose ​ possible based on the background scenes and objects  
○ Devised a ​ novel way​ for background analysis to get low-level features which could be used to recommend the best  
possible pose.  
○ Filed patent application in the US and India, ​ which is under review  
* **Camera Lite SDK**  
○ A lightweight SDK to provide Third-Party Camera Apps similar image quality as that of Samsung Camera App  
○ 3 billion captures ​ till date using the solution on a global scale  
○ High-level and low-level design and development of SDK  
* **Text to Video Emoji Content Generation using Tensorflow**  
○ An unsupervised recurrent neural network to find contextual and physical features from ​ articulated text  
○ Full-body tracking model to find body points and animate it according to temporal data from text. Got​ 88%
accuracy ​ compared to Text to Speech method.  
* **Google Camera X Extensions**  
○ Design and Implementation of the framework to provide developers to access Samsung specific image processing
solutions such as ​ HDR, night, Bokeh  
○ Contributed various interface designs which finally went to ​ AOSP. Implemented Vendor Extension for use case
realization.  
○ Co-worked with Google for a successful ​ [Google I/O](https://www.youtube.com/watch?v=kuv8uK-5CLY) and​ ​ [Samsung Developer Conference Demo](https://www.youtube.com/watch?v=S70mBGwMewY).  

**Course projects/Initiatives**  
* **Samsung Research Institute, Bangalore**  
○ Source Code Translation from Microsoft UWP to Tizen Platform  
○ Designed and developed a toolkit to automatically translate the application code from one platform to another specifically Microsoft UWP to Tizen Platform  
○ The work was based on Roslyn, XAML, C#  
* **3D modelling and navigation in VR using Leap Motion Sensor.**  
[Source Code](https://github.com/mayankanchlia/3D-Modeling-and-Navigation)
[Project Report]({{site.url}}/files/3dModelingAndNavigation.pdf)  
○ Created a more intuitive way to interact with a computer in VR using Leap Motion Sensor to track hands, and sensor data of a mobile phone to localize hands, track head and set the orientation of the player.  
○ It detects Hand gestures to track inputs from the user and recognizes it. 
○ Used Unity game engine to design the application

* **Sign language and gesture recognition**  
○ The objective of the project was to build a classifier to solve the following problems  
A) Given an image of a static gesture, predict what alphabet it represents.  
B) Given an image of a person's upper body and hand, locate the hand and classify the gesture. Since this project was a part of the ML course, image processing operations like filtering, thresholding, color segmentation etc. were not allowed. We performed geometric operations like scaling, rotating or cropping and conversion to gray-scale. We used the Scikit-Image library for this.

* **Fast Partition Recovery For Packets in Mobile Wireless Sensor Network**  
○ The objective of the project was to develop a routing protocol to communicate between sensor nodes which can be used to reduce packet loss in a random
deployment scenario with multiple sinks and a single base station and dynamic topography of nodes.  
○  I have used C++ with Omnet++ emulator and Castalia to simulate the scenario and worked on algorithm for fast partition recovery to regain connectivity in dynamic topographic network.

 
For more details, please refer to my [resume]({{site.url}}/files/Resume.pdf) or contact me. 